{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import preprocessing as pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/All_Data.csv\", index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(df['state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = pd.DataFrame(df['jobtitle'].value_counts())\n",
    "titles = titles.sort_values(by='jobtitle', ascending = False)\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles.to_csv(\"../metrics/title_distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df[\"jobtitle\"] != 'Machine Learning']\n",
    "#df = df[df[\"jobtitle\"] != 'Data Architect']\n",
    "#df = df[df[\"jobtitle\"] != 'Data Analyst']\n",
    "#df = df[df[\"jobtitle\"] != 'Data Engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(set(df['jobtitle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned = pps.raw_cleaning(df['snippet'], noun = False)\n",
    "vectorizer = TfidfVectorizer(max_df = 0.99, min_df = 0.01, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(cleaned).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df['jobtitle']\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, max_depth = None, n_estimators = 200, min_impurity_split=1e-07)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf6 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), ('knn', clf4)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4,clf5, clf6, eclf], ['Logistic Regerssion','Random Forest', 'naive Bayes', 'K neighbours',' Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(random_state=1, max_depth = None, n_estimators = 200, min_impurity_split=1e-07, oob_score = True)\n",
    "clf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf2.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf2.fit(X, y)\n",
    "words = list(vectorizer.vocabulary_.keys())\n",
    "features = pd.DataFrame(words, columns=['word'])\n",
    "features['importance'] = clf2.feature_importances_\n",
    "features.sort_values(by='importance', ascending=False, inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.to_csv(\"../metrics/feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.iloc[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try topic modeling to get features (one for each topic)\n",
    "#corpus is a two dimensional list of tuples (wordtoken, count).\n",
    "def text2corpus(texts, method= 'count'):\n",
    "    documents = pps.raw_cleaning(texts, False)\n",
    "    texts = [[word for word in document.lower().split()] for document in documents]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    if method == 'tfidf':\n",
    "        tfidf = models.TfidfModel(corpus)\n",
    "        return tfidf[corpus]\n",
    "    return corpus, dictionary\n",
    "#result = text2corpus(df['snippet'])\n",
    "corpus, dictionary = text2corpus(df['snippet'], 'count')\n",
    "model = models.LdaModel(corpus, id2word=dictionary, num_topics=100)\n",
    "#get a feature table from the topic model\n",
    "topic_features = pd.DataFrame()\n",
    "for i in range(len(corpus)):\n",
    "    one_row = {str(n):0 for n in range(100)}\n",
    "    features = model[corpus[i]]\n",
    "    for j in range(len(features)):\n",
    "        one_row[str(features[j][0])] = features[j][1]\n",
    "    topic_features = topic_features.append(pd.Series(one_row, name=str(i)))\n",
    "\n",
    "topic_features.to_csv(\"../metrics/topic_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = topic_features.iloc[:,:100]\n",
    "y = df['jobtitle']\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators = 100)\n",
    "clf3 = GaussianNB()\n",
    "#clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf4 = KNeighborsClassifier(n_neighbors=7)\n",
    "#clf6 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), ('knn', clf4)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'K neighbours',' Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
