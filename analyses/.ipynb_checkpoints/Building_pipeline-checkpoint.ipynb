{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "#my own functions cleaning raw text\n",
    "import preprocessing as pps\n",
    "import getkeywords as gkw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in data\n",
    "df = pd.read_csv(\"../../data/All_Data.csv\", index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write data distribution across states to a csv file\n",
    "pd.DataFrame(df['state'].value_counts()).to_csv(\"../metrics/state_distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter data (get rid of the jobtitles that do not go into the model)\n",
    "df = df[df[\"jobtitle\"] != 'Machine Learning']\n",
    "df = df[df[\"jobtitle\"] != 'Data Architect']\n",
    "df = df[df[\"jobtitle\"] != 'Data Analyst']\n",
    "#df = df[df[\"jobtitle\"] != 'Data Engineer']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#look at the jobtitles left\n",
    "set(df['jobtitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split and preprocess data\n",
    "data_train, data_test = pps.kfold_split(df, k=5)\n",
    "train_feature = pps.raw_cleaning(data_train['snippet'], False)\n",
    "train_labels = data_train['jobtitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build pipeline including a transformer and a classifier\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer(max_df = 0.99, min_df = 0.01,ngram_range=(1,3))),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=200)),\n",
    "])\n",
    "text_clf = text_clf.fit(train_feature, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#see how the pipeline performs on test data\n",
    "test_feature = pps.raw_cleaning(data_test['snippet'], False)\n",
    "predicted = text_clf.predict(test_feature)\n",
    "test_labels = data_test['jobtitle']\n",
    "#output = pd.DataFrame(predicted, test_labels)\n",
    "print(np.mean(predicted == test_labels)) \n",
    "#print(output)\n",
    "confusion = pd.DataFrame(confusion_matrix(predicted, test_labels, labels=list(set(test_labels))), columns = list(set(test_labels)))\n",
    "confusion = confusion.div(confusion.sum(axis=0), axis=1)\n",
    "f1s = metrics.classification_report(test_labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write the confusion matrix to a csv file\n",
    "#confusion.to_csv(\"../metrics/confusion_matrix_all.csv\")\n",
    "#dump the pipeline object to the target directory\n",
    "joblib.dump(text_clf, \"../JB_app/models/text_clf_medium.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test on one entry\n",
    "new_data = [data_test['snippet'].iloc[1]]\n",
    "new_feature = pps.raw_cleaning(new_data, False)\n",
    "prediction = text_clf.predict_proba(new_feature)\n",
    "output = pd.DataFrame()\n",
    "output['jobtitle'] = text_clf.classes_\n",
    "output['probability'] = prediction[0]\n",
    "output = output.sort_values(by='probability', ascending=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate a document * label table with each element being the probability of a document being a label\n",
    "likelihoods = pd.DataFrame(columns = list(set(df['jobtitle'])))\n",
    "for i in range(df.shape[0]):\n",
    "    new = [df['snippet'].iloc[i]]\n",
    "    feature = pps.raw_cleaning(new, False)\n",
    "    prediction = text_clf.predict_proba(feature)[0]\n",
    "    labels = text_clf.classes_\n",
    "    likelihoods = likelihoods.append(pd.Series({label:ll for label, ll in zip(labels, prediction)}, name = str(i)))\n",
    "likelihoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likelihoods.to_csv(\"../metrics/likelihoods_table_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll_table = pd.read_csv(\"../metrics/likelihoods_table_all.csv\", index_col=0)\n",
    "ll_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prototypes = gwd.get_prototypes(ll_table)\n",
    "prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfs = pd.read_csv(\"../metrics/All_tfidf_features_99.csv\", index_col=0)\n",
    "tfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "features = tfs.iloc[:,3:]\n",
    "words = list(features.columns)\n",
    "label = 'Data Scientist'\n",
    "tmp = pd.DataFrame()\n",
    "tmp['words'] = words\n",
    "tmp['tfidf'] = list(features.iloc[prototypes[label],:].sum(axis=0))\n",
    "tmp = tmp.sort_values(by = 'tfidf', ascending = False)\n",
    "tmp['words'].iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prototypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords = gkw.get_keywords(tfs.iloc[:,3:], prototypes, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords.to_csv(\"../JB_app/keywords_all_30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords = pd.read_csv(\"../JB_app/keywords_all.csv\", index_col=0)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gkw.common_keywords('Data Architect','Data Analyst',  keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = [df['snippet'].iloc[1]]\n",
    "cleaned_text = pps.raw_cleaning(new, False).iloc[0]\n",
    "cleaned_words = list(set(cleaned_text.split()))\n",
    "gkw.contributing_words(cleaned_words, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
